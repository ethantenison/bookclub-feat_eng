# Working with Profile Data

**What even is profile data???** Not hierarchical structures?!?!

Profile data refers to datasets that have complex hierachcical relationships.An example would be if you're trying to predict whether a student would pass a course. You might have demographic data on that student, but you'd probably also have data on the courses they took, absences grades etc.. There might also be a time component related to how quickly they're finishing their degree. There are a lot of layers to this, and feature engineering can help us create better models, insofar as we understand the data's structure.

\*look up variabnce of a difference **Learning objectives:**

-   THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY

## Illustrative Data: Pharmaceutical Manufacturing Monitoring

-   Company is trying to produce a drug that uses specific proteins

-   Cell are placed in a bioreactor where they produce the proteins (the yield)

-   factors like humidity and temperature can be recorded, as well as cell specific celluar data like glucose productiion and ammonia (which can negatively impact the yield)

-   Measuring glucose and ammonia is time consuming, so a spectroscopy is used to make the predictions, from 15 small reactors and 3 large reactors

![A schematic for the experimental design for pharmaceutical manufacturing.](images/09_pharm_example.png)

The goal here is to see if we can take the results from the small reactors to predict the results of the big reactors.

Looking at the spectra over multiple days we see that the intensity exhibits similar patterns in the small and large reactors. The difference being the big reactors lead to slightly higher intensities.

![](images/09_profile-small-large-bioreactors.svg){width="769" height="439"}

![](images/09_profile-small-large-bioreactors.svg)

![(a) Spectra for a small- and large-scale reactor on days 1, 7, and 14. (b) The spectra for a single reactor over 14 days.](images/09_profile-small-large-bioreactors-2.svg)

![![](images/09_profile-small-large-bioreactors.svg)](images/09_profile-small-large-bioreactors.svg)

## What are the Experimental Unit and the Unit of Prediction?

Nearly 2600 wavelengths are measured each day for two weeks for each of 15 small-scale bioreactors. This type of data forms a *hierarchical, or nested,* structure in which wavelengths are measured within each day and within each bioreactor. The key characteristic of this is that the data within a nesting is more related than data between nestings. For example, the spectra within a day are more related to each other than between different days, AND the wavelengths within the days are more correlated with each other than wavelengths between reactors.

### ðŸ¤¯WOW this is confusing

Interrelated correlations can be visualized through a plot of autocorrelations. In the plot below, we can see that the autocorrelation between wavelengths is different on different days, [confusiling]

![(a) Autocorrelations for selected lags of wavelengths for small-scale bioreactor 1 on the first day. (b) Autocorrelations for lags of days for average wavelength intensity for small-scale bioreactor 1.](images/09_profile-acf-bioreactor1-1.svg)

Figure [9.4](http://www.feat.engineering/what-are-the-experimental-unit-and-the-unit-of-prediction.html#fig:profile-acf-bioreactor1) (b) shows the autocorrelations for the first 13 lagged days. Here correlations for the first lag is greater than 0.95, with correlations tailing off fairly quickly.

So what is the unit of prediction? Spectra? Number of days to reach a certain wavelength? Because everything inside a bioreactor is independent of other bioreactors, the unit of analysis is day within a bioreactor.

The unit of analysis will help us decide how to use cross-validation to evaluate our results honestly. Leave one, or more, bioreactors out should be used.

## Reducing Background

Excess variation due to spurious sources can have a detrimental impact on the models (the book mentions principal component regression and partial least square). Removing all the background noise is almost impossible, but we can approximate it.

Spectral data deviations across reactors and days can occur because of measurement error, interference, or fluorescent, and don't have an impact on actual glucose production in the cells. To get rid of this noise, the author uses a polynomial fit on the lowest intensities. Then they take the negative residuals and subtract those data points.

![A polynomial baseline correction for the small-scale bioreactor 1, day 1 intensities.](images/09_noise_reduction.png)

## Reducing Other Noise

There can also be systemic variation between bioreactor measurement instruments rather than difference in the amount of molecules being sampled. You saw in the graph comparing small and large bioreactors that although the peaks were the same, the intensity appeared higher for large ones. Given that these peaks are most important, we can rescale the data across reactors to ensure results are comparable.

The author uses **standard normal variate (SNV)** from spectroscopy literature to rescale the data based on the mean and standard deviation. Since these measures can be influenced by outliers, **trimming** is used to take out extreme values.

Figure [9.6](http://www.feat.engineering/reducing-other-noise.html#fig:profile-standardized) compares the profiles of the spectrum with the lowest variation and highest variation for (a) the baseline corrected data across all days and small-scale bioreactors. This figure demonstrates that the amplitudes of the profiles can vary greatly.

![Figure 9.6: (a) The baseline-corrected intensities for the spectra that are the most- and least variable. (b) The spectra after standardizing each to have a mean of 0 and standard deviation of 1.](images/09_profile-standardized-1.svg)

Another source of noise here was the intensity measurements for **EACH** wavelength within a spectrum. The author uses splines and moving averages to smooth out the intensities. The key here was to select the correct number of points to include in the moving averages.

![Figure 9.7: The moving average of lengths 5, 15, and 50 applied to the first day of the first small-scale bioreactor for wavelengths 950 through 1200.](images/09_profile-smoothed-1.svg)

## Exploiting Correlation

The previous two chapter were about reducing the noise , which allows us to make better predictions. However, this does not help us deal with the correlation between features -in this case the correlation between wavelengths within a spectra (I think?).\

One approach to dealing with correlation is principal component analysis (PCA), which gets rid of the correlation between features, but isn't guranteed to improve the predictive power because the output isn't taken into account.

![Figure 9.8: PCA dimension reduction applied across all small-scale data. (a) A scree plot of the cumulative variability explained across components. (b) Scatterplots of Glucose and the first three principal components.](images/09_profile-small-pca-1.svg) ![Figure 9.8: PCA dimension reduction applied across all small-scale data. (a) A scree plot of the cumulative variability explained across components. (b) Scatterplots of Glucose and the first three principal components.](images/09_profile-small-pca-1.svg){width="600" height="500"}

Using PCA, the 80% of the variation can be explained by using just 11 components, seen in the scree plot above. That being said, each component does not contain contain much predictive power to the response. For this reason, partial least squares should have been used. (Not sure why they didn't?)

A second approach to deal with the correlation is to take the first-order derivative within each profile. To compute first-order differentiation, the response at the $(pâˆ’1)^{st}$ value in the profile is subtracted from the response at the $p^{th}$ value in the profile. This difference represents the rate of change of the response between consecutive measurements in the profile. Larger changes correspond to a larger movement and could potentially be related to the signal in the response. This means that the autocorrelation between profiles should be greatly reduced.

![Figure 9.9: Autocorrelations before and after taking derivatives of the spectra.](images/09_profile-acf-bioreactor1-derivative-1.svg)

We can see in **Figure 9.9** that using the first order derivatives dramatically takes out autocorrelation after the 3rd day lag.

Taken altogether, subsequent preprocessing steps nearly eliminate within-spectra drift has been removed and most of the trends that are unrelated to the peaks have been minimized.

![Figure 9.10: Spectra for the first day of the first small-scale bioreactor where the preprocessing steps have been sequentially applied.](images/09_profile-bioreactor1-day1-before-after-1.svg)

<details>

<summary>Meeting chat log</summary>

    LOG

</details>
